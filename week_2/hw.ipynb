{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "147f6d5d-63d2-43de-8485-efae596b3485",
   "metadata": {},
   "source": [
    "## Packages import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0b2378b-00a1-486a-8971-b20a74447c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dae04ab-e2c7-4a95-8655-af105f59fb71",
   "metadata": {},
   "source": [
    "## Q1.Install MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3907142c-254e-4499-b47a-ada664509ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlflow, version 1.26.1\n"
     ]
    }
   ],
   "source": [
    "!mlflow --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58055484-c753-463b-aa17-799a28acb925",
   "metadata": {},
   "source": [
    "**Q1**: 1.26.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcafa035-bec7-4e61-bc07-fc4dd3f42fba",
   "metadata": {},
   "source": [
    "## Q2. Download and preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fb64e02-bdce-4d2c-bed8-6a7f91607286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Projects/mlops/week_2\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "772f6cd6-0850-4861-a820-73ac967e88a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p input_data\n",
    "!mkdir -p models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b6b7573-7c6c-4737-b489-ae603179a261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-05-30 00:16:01--  https://s3.amazonaws.com/nyc-tlc/trip+data/green_tripdata_2021-01.parquet\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.15.22\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.15.22|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1333519 (1,3M) [binary/octet-stream]\n",
      "Saving to: ‘input_data/green_tripdata_2021-01.parquet’\n",
      "\n",
      "input_data/green_tr 100%[===================>]   1,27M  1,65MB/s    in 0,8s    \n",
      "\n",
      "2022-05-30 00:16:03 (1,65 MB/s) - ‘input_data/green_tripdata_2021-01.parquet’ saved [1333519/1333519]\n",
      "\n",
      "--2022-05-30 00:16:03--  https://s3.amazonaws.com/nyc-tlc/trip+data/green_tripdata_2021-02.parquet\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.15.22\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.15.22|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1145679 (1,1M) [binary/octet-stream]\n",
      "Saving to: ‘input_data/green_tripdata_2021-02.parquet’\n",
      "\n",
      "input_data/green_tr 100%[===================>]   1,09M  1,42MB/s    in 0,8s    \n",
      "\n",
      "2022-05-30 00:16:04 (1,42 MB/s) - ‘input_data/green_tripdata_2021-02.parquet’ saved [1145679/1145679]\n",
      "\n",
      "--2022-05-30 00:16:04--  https://s3.amazonaws.com/nyc-tlc/trip+data/green_tripdata_2021-03.parquet\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.15.22\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.15.22|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1474538 (1,4M) [binary/octet-stream]\n",
      "Saving to: ‘input_data/green_tripdata_2021-03.parquet’\n",
      "\n",
      "input_data/green_tr 100%[===================>]   1,41M  2,03MB/s    in 0,7s    \n",
      "\n",
      "2022-05-30 00:16:05 (2,03 MB/s) - ‘input_data/green_tripdata_2021-03.parquet’ saved [1474538/1474538]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://s3.amazonaws.com/nyc-tlc/trip+data/green_tripdata_2021-01.parquet -O input_data/green_tripdata_2021-01.parquet\n",
    "!wget https://s3.amazonaws.com/nyc-tlc/trip+data/green_tripdata_2021-02.parquet -O input_data/green_tripdata_2021-02.parquet\n",
    "!wget https://s3.amazonaws.com/nyc-tlc/trip+data/green_tripdata_2021-03.parquet -O input_data/green_tripdata_2021-03.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "746d07aa-c556-4d9f-99f8-6c1f236b4cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python preprocess_data.py --raw_data_path input_data --dest_path ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9340c34-055f-4ff9-bd23-9013aa7c751b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 files\n"
     ]
    }
   ],
   "source": [
    "data_folder_path = os.path.join(os.getcwd(), 'data')\n",
    "files = [path for path in os.listdir(data_folder_path) if os.path.isfile(os.path.join(data_folder_path, path))]\n",
    "\n",
    "print(f\"There are {len(files)} files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cca5e28-e758-43c8-8cca-e21956482839",
   "metadata": {},
   "source": [
    "**Q2**: 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589217a6-4b35-44be-9f1e-22c1c15de225",
   "metadata": {},
   "source": [
    "## Q3. Train a model with autolog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6f0506-dba2-48b9-a256-c508df8e711a",
   "metadata": {},
   "source": [
    "The code of `train.py` is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf1afff-da14-40a9-a17d-7df47d3c736d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "import mlflow\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "def load_pickle(filename: str):\n",
    "    return joblib.load(filename)\n",
    "\n",
    "\n",
    "def run(data_path):\n",
    "    X_train, y_train = load_pickle(os.path.join(data_path, \"train.pkl\"))\n",
    "    X_valid, y_valid = load_pickle(os.path.join(data_path, \"valid.pkl\"))\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        rf = RandomForestRegressor(max_depth=10, random_state=0)\n",
    "        rf.fit(X_train, y_train)\n",
    "        y_pred = rf.predict(X_valid)\n",
    "\n",
    "        rmse = mean_squared_error(y_valid, y_pred, squared=False)\n",
    "        # mlflow.log_metric(\"rmse\", rmse)\n",
    "        print(f\"RMSE is {round(rmse, 2)}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--data_path\",\n",
    "        default=\"./data\",\n",
    "        help=\"the location where the processed NYC taxi trip data was saved.\"\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # In order to access the UI, it is necessary to run the MLFlow server:\n",
    "    #   mlflow ui --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./mlruns\n",
    "    mlflow.mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "    mlflow.set_experiment(\"02-experiment-tracking\")\n",
    "    mlflow.sklearn.autolog()\n",
    "\n",
    "    run(args.data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e7baee-45b6-4a4a-98ea-32345c4ffe44",
   "metadata": {},
   "source": [
    "![title](./Q3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc34135-607a-4fd0-8ce2-4f4407ca0181",
   "metadata": {},
   "source": [
    "**Q3**: 17"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42fd0d9-885c-4940-bffd-fa9b888c7670",
   "metadata": {},
   "source": [
    "## Q4. Launch the tracking server locally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f41794-8c02-45f3-92cb-b0c33944d157",
   "metadata": {},
   "source": [
    "The tracking server should be run by means of the following command:\n",
    "\n",
    "`!mlflow ui --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./mlruns`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4edd42-edb6-4c5f-bc85-eecaf8c63e46",
   "metadata": {},
   "source": [
    "**Q4**: `--default-artifact-root`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1561630f-a4fc-4c49-8d70-0eff9c8bb108",
   "metadata": {},
   "source": [
    "## Q5. Tune the hyperparameters of the model\n",
    "\n",
    "The code of `hpo.py` is as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1aa653b-83d3-4728-80cc-79d669f431d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "import mlflow\n",
    "import numpy as np\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "from hyperopt.pyll import scope\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"random-forest-hyperopt\")\n",
    "\n",
    "\n",
    "def load_pickle(filename: str):\n",
    "    return joblib.load(filename)\n",
    "\n",
    "\n",
    "def run(data_path, num_trials):\n",
    "    X_train, y_train = load_pickle(os.path.join(data_path, \"train.pkl\"))\n",
    "    X_valid, y_valid = load_pickle(os.path.join(data_path, \"valid.pkl\"))\n",
    "\n",
    "    def objective(params):\n",
    "        with mlflow.start_run():\n",
    "            mlflow.set_tag(\"model\", \"RandomForestRegressor\")\n",
    "            mlflow.log_params(params)\n",
    "\n",
    "            rf = RandomForestRegressor(**params)\n",
    "            rf.fit(X_train, y_train)\n",
    "            y_pred = rf.predict(X_valid)\n",
    "            rmse = mean_squared_error(y_valid, y_pred, squared=False)\n",
    "            mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "        return {'loss': rmse, 'status': STATUS_OK}\n",
    "\n",
    "    search_space = {\n",
    "        'max_depth': scope.int(hp.quniform('max_depth', 1, 20, 1)),\n",
    "        'n_estimators': scope.int(hp.quniform('n_estimators', 10, 50, 1)),\n",
    "        'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 10, 1)),\n",
    "        'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 4, 1)),\n",
    "        'random_state': 42\n",
    "    }\n",
    "\n",
    "    rstate = np.random.default_rng(42)  # for reproducible results\n",
    "    fmin(\n",
    "        fn=objective,\n",
    "        space=search_space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=num_trials,\n",
    "        trials=Trials(),\n",
    "        rstate=rstate\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--data_path\",\n",
    "        default=\"./data\",\n",
    "        help=\"the location where the processed NYC taxi trip data was saved.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--max_evals\",\n",
    "        default=50,\n",
    "        help=\"the number of parameter evaluations for the optimizer to explore.\"\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    run(args.data_path, args.max_evals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618b913e-22d3-4881-b3e0-928c9521c6e4",
   "metadata": {},
   "source": [
    "![title](./Q5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7d8d39-a009-43b8-9345-d05321937ce7",
   "metadata": {},
   "source": [
    "**Q5**: 6.628"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a224a35f-84fc-460d-a090-92ace53b70df",
   "metadata": {},
   "source": [
    "## Q6. Promote the best model to the model registry\n",
    "\n",
    "The code of `register_model.py` is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42067286-90d5-4cac-911f-afe246fd113c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "import mlflow\n",
    "from hyperopt import hp, space_eval\n",
    "from hyperopt.pyll import scope\n",
    "from mlflow.entities import ViewType\n",
    "from mlflow.tracking import MlflowClient\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "HPO_EXPERIMENT_NAME = \"random-forest-hyperopt\"\n",
    "EXPERIMENT_NAME = \"random-forest-best-models\"\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "mlflow.sklearn.autolog()\n",
    "\n",
    "SPACE = {\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 1, 20, 1)),\n",
    "    'n_estimators': scope.int(hp.quniform('n_estimators', 10, 50, 1)),\n",
    "    'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 10, 1)),\n",
    "    'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 4, 1)),\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "\n",
    "def load_pickle(filename: str):\n",
    "    return joblib.load(filename)\n",
    "\n",
    "\n",
    "def train_and_log_model(data_path, params):\n",
    "    X_train, y_train = load_pickle(os.path.join(data_path, \"train.pkl\"))\n",
    "    X_valid, y_valid = load_pickle(os.path.join(data_path, \"valid.pkl\"))\n",
    "    X_test, y_test = load_pickle(os.path.join(data_path, \"test.pkl\"))\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        params = space_eval(SPACE, params)\n",
    "        rf = RandomForestRegressor(**params)\n",
    "        rf.fit(X_train, y_train)\n",
    "\n",
    "        # evaluate model on the validation and test sets\n",
    "        valid_rmse = mean_squared_error(y_valid, rf.predict(X_valid), squared=False)\n",
    "        mlflow.log_metric(\"valid_rmse\", valid_rmse)\n",
    "        test_rmse = mean_squared_error(y_test, rf.predict(X_test), squared=False)\n",
    "        mlflow.log_metric(\"test_rmse\", test_rmse)\n",
    "\n",
    "\n",
    "def run(data_path, log_top):\n",
    "    client = MlflowClient()\n",
    "\n",
    "    # retrieve the top_n model runs and log the models to MLflow\n",
    "    experiment = client.get_experiment_by_name(HPO_EXPERIMENT_NAME)\n",
    "    runs = client.search_runs(\n",
    "        experiment_ids=experiment.experiment_id,\n",
    "        run_view_type=ViewType.ACTIVE_ONLY,\n",
    "        max_results=log_top,\n",
    "        order_by=[\"metrics.rmse ASC\"]\n",
    "    )\n",
    "    for run in runs:\n",
    "        #train_and_log_model(data_path=data_path, params=run.data.params)\n",
    "        pass\n",
    "\n",
    "    # select the model with the lowest test RMSE\n",
    "    experiment = client.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "    best_run = client.search_runs(\n",
    "        experiment_ids=experiment.experiment_id,\n",
    "        run_view_type=ViewType.ACTIVE_ONLY,\n",
    "        max_results=1\n",
    "    )[0]\n",
    "    print(best_run)\n",
    "\n",
    "    # register the best model\n",
    "    run_id = best_run.info.run_id\n",
    "    model_uri = f\"runs:/{run_id}/models\"\n",
    "    print(f\"Model URI is {model_uri}\")\n",
    "    mlflow.register_model(model_uri=model_uri, name=\"nyc-taxi-regressor\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--data_path\",\n",
    "        default=\"./data\",\n",
    "        help=\"the location where the processed NYC taxi trip data was saved.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--top_n\",\n",
    "        default=5,\n",
    "        type=int,\n",
    "        help=\"the top 'top_n' models will be evaluated to decide which model to promote.\"\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    run(args.data_path, args.top_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14626b88-4cff-4c4b-979d-89df8546dd10",
   "metadata": {},
   "source": [
    "![title](./Q6a.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314b167b-4602-498c-9725-5c791559a1dc",
   "metadata": {},
   "source": [
    "![title](./Q6b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50912c97-4814-493b-9a2d-e77a3531aaaa",
   "metadata": {},
   "source": [
    "**Q6**: 6.55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4b3591-18e6-4975-9081-41c000e27644",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
